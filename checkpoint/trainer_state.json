{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.998000444345701,
  "eval_steps": 500,
  "global_step": 3375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008886914019106865,
      "grad_norm": 4.5634494776814885,
      "learning_rate": 2.9585798816568047e-06,
      "loss": 2.3579,
      "step": 10
    },
    {
      "epoch": 0.01777382803821373,
      "grad_norm": 2.7071866924969616,
      "learning_rate": 5.917159763313609e-06,
      "loss": 2.0851,
      "step": 20
    },
    {
      "epoch": 0.026660742057320594,
      "grad_norm": 1.111839027681382,
      "learning_rate": 8.875739644970414e-06,
      "loss": 1.7416,
      "step": 30
    },
    {
      "epoch": 0.03554765607642746,
      "grad_norm": 0.6110208260081906,
      "learning_rate": 1.1834319526627219e-05,
      "loss": 1.4806,
      "step": 40
    },
    {
      "epoch": 0.04443457009553432,
      "grad_norm": 0.5868557936372714,
      "learning_rate": 1.4792899408284025e-05,
      "loss": 1.3449,
      "step": 50
    },
    {
      "epoch": 0.05332148411464119,
      "grad_norm": 0.59953076317076,
      "learning_rate": 1.7751479289940828e-05,
      "loss": 1.1987,
      "step": 60
    },
    {
      "epoch": 0.06220839813374806,
      "grad_norm": 0.6095731301665784,
      "learning_rate": 2.0710059171597635e-05,
      "loss": 1.1279,
      "step": 70
    },
    {
      "epoch": 0.07109531215285492,
      "grad_norm": 0.6472451978606585,
      "learning_rate": 2.3668639053254438e-05,
      "loss": 1.036,
      "step": 80
    },
    {
      "epoch": 0.07998222617196178,
      "grad_norm": 0.6738397211684677,
      "learning_rate": 2.6627218934911247e-05,
      "loss": 0.9809,
      "step": 90
    },
    {
      "epoch": 0.08886914019106865,
      "grad_norm": 0.7319888863676356,
      "learning_rate": 2.958579881656805e-05,
      "loss": 0.939,
      "step": 100
    },
    {
      "epoch": 0.09775605421017551,
      "grad_norm": 0.7425077329155809,
      "learning_rate": 3.254437869822485e-05,
      "loss": 0.928,
      "step": 110
    },
    {
      "epoch": 0.10664296822928238,
      "grad_norm": 0.7539656748552004,
      "learning_rate": 3.5502958579881656e-05,
      "loss": 0.8654,
      "step": 120
    },
    {
      "epoch": 0.11552988224838924,
      "grad_norm": 0.7285522594554914,
      "learning_rate": 3.846153846153846e-05,
      "loss": 0.871,
      "step": 130
    },
    {
      "epoch": 0.12441679626749612,
      "grad_norm": 0.7647062859311643,
      "learning_rate": 4.142011834319527e-05,
      "loss": 0.8407,
      "step": 140
    },
    {
      "epoch": 0.13330371028660298,
      "grad_norm": 0.8189528978159378,
      "learning_rate": 4.437869822485207e-05,
      "loss": 0.8513,
      "step": 150
    },
    {
      "epoch": 0.14219062430570983,
      "grad_norm": 0.8371372829141263,
      "learning_rate": 4.7337278106508875e-05,
      "loss": 0.8315,
      "step": 160
    },
    {
      "epoch": 0.1510775383248167,
      "grad_norm": 0.7442399174463632,
      "learning_rate": 5.029585798816568e-05,
      "loss": 0.8524,
      "step": 170
    },
    {
      "epoch": 0.15996445234392356,
      "grad_norm": 0.751174465350874,
      "learning_rate": 5.3254437869822495e-05,
      "loss": 0.7845,
      "step": 180
    },
    {
      "epoch": 0.16885136636303044,
      "grad_norm": 0.7935595566075814,
      "learning_rate": 5.621301775147929e-05,
      "loss": 0.7772,
      "step": 190
    },
    {
      "epoch": 0.1777382803821373,
      "grad_norm": 0.908451461235776,
      "learning_rate": 5.91715976331361e-05,
      "loss": 0.746,
      "step": 200
    },
    {
      "epoch": 0.18662519440124417,
      "grad_norm": 0.7947346085378496,
      "learning_rate": 6.21301775147929e-05,
      "loss": 0.7721,
      "step": 210
    },
    {
      "epoch": 0.19551210842035102,
      "grad_norm": 0.9025620463531908,
      "learning_rate": 6.50887573964497e-05,
      "loss": 0.7521,
      "step": 220
    },
    {
      "epoch": 0.2043990224394579,
      "grad_norm": 0.8559958436632991,
      "learning_rate": 6.804733727810652e-05,
      "loss": 0.7434,
      "step": 230
    },
    {
      "epoch": 0.21328593645856475,
      "grad_norm": 0.9048783732309927,
      "learning_rate": 7.100591715976331e-05,
      "loss": 0.6702,
      "step": 240
    },
    {
      "epoch": 0.22217285047767163,
      "grad_norm": 0.8015819932734383,
      "learning_rate": 7.396449704142012e-05,
      "loss": 0.687,
      "step": 250
    },
    {
      "epoch": 0.23105976449677848,
      "grad_norm": 0.7663400748096666,
      "learning_rate": 7.692307692307693e-05,
      "loss": 0.6915,
      "step": 260
    },
    {
      "epoch": 0.23994667851588536,
      "grad_norm": 0.8074528527167362,
      "learning_rate": 7.988165680473373e-05,
      "loss": 0.6544,
      "step": 270
    },
    {
      "epoch": 0.24883359253499224,
      "grad_norm": 0.7894696922871971,
      "learning_rate": 8.284023668639054e-05,
      "loss": 0.7019,
      "step": 280
    },
    {
      "epoch": 0.2577205065540991,
      "grad_norm": 0.6861692808230726,
      "learning_rate": 8.579881656804734e-05,
      "loss": 0.653,
      "step": 290
    },
    {
      "epoch": 0.26660742057320597,
      "grad_norm": 0.7280970858674709,
      "learning_rate": 8.875739644970414e-05,
      "loss": 0.6499,
      "step": 300
    },
    {
      "epoch": 0.2754943345923128,
      "grad_norm": 0.6692235700387283,
      "learning_rate": 9.171597633136096e-05,
      "loss": 0.6333,
      "step": 310
    },
    {
      "epoch": 0.28438124861141967,
      "grad_norm": 0.7673090850947397,
      "learning_rate": 9.467455621301775e-05,
      "loss": 0.6296,
      "step": 320
    },
    {
      "epoch": 0.2932681626305266,
      "grad_norm": 0.6091475442952986,
      "learning_rate": 9.763313609467456e-05,
      "loss": 0.6027,
      "step": 330
    },
    {
      "epoch": 0.3021550766496334,
      "grad_norm": 0.6330519158074912,
      "learning_rate": 9.99998929935376e-05,
      "loss": 0.6493,
      "step": 340
    },
    {
      "epoch": 0.3110419906687403,
      "grad_norm": 0.5930236662731823,
      "learning_rate": 9.99961478154451e-05,
      "loss": 0.5963,
      "step": 350
    },
    {
      "epoch": 0.3199289046878471,
      "grad_norm": 0.5375170875819117,
      "learning_rate": 9.998705277223926e-05,
      "loss": 0.6096,
      "step": 360
    },
    {
      "epoch": 0.32881581870695403,
      "grad_norm": 0.5311975748327782,
      "learning_rate": 9.997260883714015e-05,
      "loss": 0.6007,
      "step": 370
    },
    {
      "epoch": 0.3377027327260609,
      "grad_norm": 0.6630302820915167,
      "learning_rate": 9.995281755572892e-05,
      "loss": 0.5681,
      "step": 380
    },
    {
      "epoch": 0.34658964674516773,
      "grad_norm": 0.5624933798839986,
      "learning_rate": 9.992768104578247e-05,
      "loss": 0.6101,
      "step": 390
    },
    {
      "epoch": 0.3554765607642746,
      "grad_norm": 0.5328348553136584,
      "learning_rate": 9.989720199704678e-05,
      "loss": 0.6413,
      "step": 400
    },
    {
      "epoch": 0.3643634747833815,
      "grad_norm": 0.5816384983206061,
      "learning_rate": 9.986138367094912e-05,
      "loss": 0.594,
      "step": 410
    },
    {
      "epoch": 0.37325038880248834,
      "grad_norm": 0.5394385764166408,
      "learning_rate": 9.982022990024901e-05,
      "loss": 0.6289,
      "step": 420
    },
    {
      "epoch": 0.3821373028215952,
      "grad_norm": 0.5862208030001651,
      "learning_rate": 9.97737450886282e-05,
      "loss": 0.6078,
      "step": 430
    },
    {
      "epoch": 0.39102421684070204,
      "grad_norm": 0.45979782077575476,
      "learning_rate": 9.972193421021936e-05,
      "loss": 0.5895,
      "step": 440
    },
    {
      "epoch": 0.39991113085980895,
      "grad_norm": 0.5430459277595852,
      "learning_rate": 9.966480280907382e-05,
      "loss": 0.5678,
      "step": 450
    },
    {
      "epoch": 0.4087980448789158,
      "grad_norm": 0.4889113244103451,
      "learning_rate": 9.960235699856837e-05,
      "loss": 0.5469,
      "step": 460
    },
    {
      "epoch": 0.41768495889802265,
      "grad_norm": 0.5660865061322722,
      "learning_rate": 9.953460346075112e-05,
      "loss": 0.5633,
      "step": 470
    },
    {
      "epoch": 0.4265718729171295,
      "grad_norm": 0.47050777671604227,
      "learning_rate": 9.946154944562637e-05,
      "loss": 0.6107,
      "step": 480
    },
    {
      "epoch": 0.4354587869362364,
      "grad_norm": 0.502616446590875,
      "learning_rate": 9.938320277037892e-05,
      "loss": 0.6037,
      "step": 490
    },
    {
      "epoch": 0.44434570095534326,
      "grad_norm": 0.4733921462471889,
      "learning_rate": 9.929957181853757e-05,
      "loss": 0.5967,
      "step": 500
    },
    {
      "epoch": 0.4532326149744501,
      "grad_norm": 0.47201156918933346,
      "learning_rate": 9.921066553907803e-05,
      "loss": 0.6034,
      "step": 510
    },
    {
      "epoch": 0.46211952899355696,
      "grad_norm": 0.532503068514872,
      "learning_rate": 9.911649344546529e-05,
      "loss": 0.5707,
      "step": 520
    },
    {
      "epoch": 0.47100644301266387,
      "grad_norm": 0.5001500956169931,
      "learning_rate": 9.901706561463569e-05,
      "loss": 0.6307,
      "step": 530
    },
    {
      "epoch": 0.4798933570317707,
      "grad_norm": 0.5212869075778421,
      "learning_rate": 9.891239268591859e-05,
      "loss": 0.5821,
      "step": 540
    },
    {
      "epoch": 0.48878027105087757,
      "grad_norm": 0.4359014801645079,
      "learning_rate": 9.880248585989791e-05,
      "loss": 0.5794,
      "step": 550
    },
    {
      "epoch": 0.4976671850699845,
      "grad_norm": 0.4339480422834693,
      "learning_rate": 9.868735689721362e-05,
      "loss": 0.5367,
      "step": 560
    },
    {
      "epoch": 0.5065540990890913,
      "grad_norm": 0.45736191092678335,
      "learning_rate": 9.856701811730329e-05,
      "loss": 0.5851,
      "step": 570
    },
    {
      "epoch": 0.5154410131081982,
      "grad_norm": 0.6435861236204407,
      "learning_rate": 9.84414823970838e-05,
      "loss": 0.5824,
      "step": 580
    },
    {
      "epoch": 0.524327927127305,
      "grad_norm": 0.5584750395537829,
      "learning_rate": 9.831076316957347e-05,
      "loss": 0.5346,
      "step": 590
    },
    {
      "epoch": 0.5332148411464119,
      "grad_norm": 0.5917941965940996,
      "learning_rate": 9.817487442245468e-05,
      "loss": 0.5278,
      "step": 600
    },
    {
      "epoch": 0.5421017551655187,
      "grad_norm": 0.45834645397294416,
      "learning_rate": 9.803383069657705e-05,
      "loss": 0.5615,
      "step": 610
    },
    {
      "epoch": 0.5509886691846256,
      "grad_norm": 0.43081079003945105,
      "learning_rate": 9.788764708440154e-05,
      "loss": 0.5318,
      "step": 620
    },
    {
      "epoch": 0.5598755832037325,
      "grad_norm": 0.4302073917884946,
      "learning_rate": 9.773633922838544e-05,
      "loss": 0.5343,
      "step": 630
    },
    {
      "epoch": 0.5687624972228393,
      "grad_norm": 0.46039202487589354,
      "learning_rate": 9.757992331930854e-05,
      "loss": 0.5877,
      "step": 640
    },
    {
      "epoch": 0.5776494112419462,
      "grad_norm": 0.3605465271126442,
      "learning_rate": 9.741841609454067e-05,
      "loss": 0.5334,
      "step": 650
    },
    {
      "epoch": 0.5865363252610531,
      "grad_norm": 0.39273430640075735,
      "learning_rate": 9.725183483625065e-05,
      "loss": 0.5507,
      "step": 660
    },
    {
      "epoch": 0.5954232392801599,
      "grad_norm": 0.4254482548598903,
      "learning_rate": 9.708019736955702e-05,
      "loss": 0.5118,
      "step": 670
    },
    {
      "epoch": 0.6043101532992669,
      "grad_norm": 0.3988051385505128,
      "learning_rate": 9.69035220606207e-05,
      "loss": 0.5232,
      "step": 680
    },
    {
      "epoch": 0.6131970673183736,
      "grad_norm": 0.42958668295228936,
      "learning_rate": 9.672182781467965e-05,
      "loss": 0.5144,
      "step": 690
    },
    {
      "epoch": 0.6220839813374806,
      "grad_norm": 0.42042239005350224,
      "learning_rate": 9.653513407402594e-05,
      "loss": 0.5711,
      "step": 700
    },
    {
      "epoch": 0.6309708953565875,
      "grad_norm": 0.4472929239226922,
      "learning_rate": 9.634346081592526e-05,
      "loss": 0.5288,
      "step": 710
    },
    {
      "epoch": 0.6398578093756943,
      "grad_norm": 0.5369451258632771,
      "learning_rate": 9.614682855047938e-05,
      "loss": 0.5566,
      "step": 720
    },
    {
      "epoch": 0.6487447233948012,
      "grad_norm": 0.45342334002792173,
      "learning_rate": 9.594525831843122e-05,
      "loss": 0.5591,
      "step": 730
    },
    {
      "epoch": 0.6576316374139081,
      "grad_norm": 0.394008297780824,
      "learning_rate": 9.573877168891364e-05,
      "loss": 0.5355,
      "step": 740
    },
    {
      "epoch": 0.6665185514330149,
      "grad_norm": 0.394068052311928,
      "learning_rate": 9.552739075714124e-05,
      "loss": 0.529,
      "step": 750
    },
    {
      "epoch": 0.6754054654521218,
      "grad_norm": 0.39425977544644625,
      "learning_rate": 9.531113814204611e-05,
      "loss": 0.5433,
      "step": 760
    },
    {
      "epoch": 0.6842923794712286,
      "grad_norm": 0.45023849962237716,
      "learning_rate": 9.50900369838575e-05,
      "loss": 0.5315,
      "step": 770
    },
    {
      "epoch": 0.6931792934903355,
      "grad_norm": 0.41031070159157995,
      "learning_rate": 9.486411094162562e-05,
      "loss": 0.549,
      "step": 780
    },
    {
      "epoch": 0.7020662075094424,
      "grad_norm": 0.4155675603924603,
      "learning_rate": 9.463338419069007e-05,
      "loss": 0.5273,
      "step": 790
    },
    {
      "epoch": 0.7109531215285492,
      "grad_norm": 0.4355700835967273,
      "learning_rate": 9.439788142009289e-05,
      "loss": 0.5531,
      "step": 800
    },
    {
      "epoch": 0.7198400355476561,
      "grad_norm": 0.4167176882276889,
      "learning_rate": 9.415762782993673e-05,
      "loss": 0.5373,
      "step": 810
    },
    {
      "epoch": 0.728726949566763,
      "grad_norm": 0.3827553931538928,
      "learning_rate": 9.391264912868827e-05,
      "loss": 0.4979,
      "step": 820
    },
    {
      "epoch": 0.7376138635858698,
      "grad_norm": 0.4421787539326072,
      "learning_rate": 9.366297153042727e-05,
      "loss": 0.5542,
      "step": 830
    },
    {
      "epoch": 0.7465007776049767,
      "grad_norm": 0.4170221277614827,
      "learning_rate": 9.340862175204157e-05,
      "loss": 0.5116,
      "step": 840
    },
    {
      "epoch": 0.7553876916240836,
      "grad_norm": 0.3709151874251234,
      "learning_rate": 9.314962701036817e-05,
      "loss": 0.5532,
      "step": 850
    },
    {
      "epoch": 0.7642746056431904,
      "grad_norm": 0.3644616873430807,
      "learning_rate": 9.28860150192809e-05,
      "loss": 0.5336,
      "step": 860
    },
    {
      "epoch": 0.7731615196622973,
      "grad_norm": 0.4380900249536079,
      "learning_rate": 9.261781398672489e-05,
      "loss": 0.5373,
      "step": 870
    },
    {
      "epoch": 0.7820484336814041,
      "grad_norm": 0.5052977790190692,
      "learning_rate": 9.234505261169819e-05,
      "loss": 0.5364,
      "step": 880
    },
    {
      "epoch": 0.790935347700511,
      "grad_norm": 0.4162853261516892,
      "learning_rate": 9.206776008118075e-05,
      "loss": 0.5436,
      "step": 890
    },
    {
      "epoch": 0.7998222617196179,
      "grad_norm": 0.3891855806098399,
      "learning_rate": 9.178596606701129e-05,
      "loss": 0.5344,
      "step": 900
    },
    {
      "epoch": 0.8087091757387247,
      "grad_norm": 0.4099587499459908,
      "learning_rate": 9.149970072271226e-05,
      "loss": 0.5136,
      "step": 910
    },
    {
      "epoch": 0.8175960897578316,
      "grad_norm": 0.47781002943970025,
      "learning_rate": 9.120899468026327e-05,
      "loss": 0.4953,
      "step": 920
    },
    {
      "epoch": 0.8264830037769385,
      "grad_norm": 0.4159685933432773,
      "learning_rate": 9.091387904682318e-05,
      "loss": 0.5243,
      "step": 930
    },
    {
      "epoch": 0.8353699177960453,
      "grad_norm": 0.42964050425452066,
      "learning_rate": 9.061438540140161e-05,
      "loss": 0.5174,
      "step": 940
    },
    {
      "epoch": 0.8442568318151522,
      "grad_norm": 0.45327621479379887,
      "learning_rate": 9.031054579147973e-05,
      "loss": 0.5127,
      "step": 950
    },
    {
      "epoch": 0.853143745834259,
      "grad_norm": 0.4092000072517791,
      "learning_rate": 9.0002392729581e-05,
      "loss": 0.5269,
      "step": 960
    },
    {
      "epoch": 0.8620306598533659,
      "grad_norm": 0.39057053868450115,
      "learning_rate": 8.968995918979216e-05,
      "loss": 0.5731,
      "step": 970
    },
    {
      "epoch": 0.8709175738724728,
      "grad_norm": 0.4253679164536352,
      "learning_rate": 8.937327860423486e-05,
      "loss": 0.5476,
      "step": 980
    },
    {
      "epoch": 0.8798044878915796,
      "grad_norm": 0.3874213812386031,
      "learning_rate": 8.905238485948815e-05,
      "loss": 0.525,
      "step": 990
    },
    {
      "epoch": 0.8886914019106865,
      "grad_norm": 0.3882763235604074,
      "learning_rate": 8.872731229296256e-05,
      "loss": 0.5184,
      "step": 1000
    },
    {
      "epoch": 0.8975783159297934,
      "grad_norm": 0.39078600100171995,
      "learning_rate": 8.839809568922564e-05,
      "loss": 0.5131,
      "step": 1010
    },
    {
      "epoch": 0.9064652299489002,
      "grad_norm": 0.5400567715719827,
      "learning_rate": 8.806477027627998e-05,
      "loss": 0.4855,
      "step": 1020
    },
    {
      "epoch": 0.9153521439680071,
      "grad_norm": 0.3638839446496075,
      "learning_rate": 8.772737172179348e-05,
      "loss": 0.5553,
      "step": 1030
    },
    {
      "epoch": 0.9242390579871139,
      "grad_norm": 0.3890383812360078,
      "learning_rate": 8.738593612928283e-05,
      "loss": 0.5078,
      "step": 1040
    },
    {
      "epoch": 0.9331259720062208,
      "grad_norm": 0.3793354613054678,
      "learning_rate": 8.704050003425015e-05,
      "loss": 0.5316,
      "step": 1050
    },
    {
      "epoch": 0.9420128860253277,
      "grad_norm": 0.4168408722054678,
      "learning_rate": 8.66911004002735e-05,
      "loss": 0.5247,
      "step": 1060
    },
    {
      "epoch": 0.9508998000444345,
      "grad_norm": 0.39706559165768185,
      "learning_rate": 8.633777461505166e-05,
      "loss": 0.5048,
      "step": 1070
    },
    {
      "epoch": 0.9597867140635414,
      "grad_norm": 0.3950631222299009,
      "learning_rate": 8.59805604864033e-05,
      "loss": 0.5141,
      "step": 1080
    },
    {
      "epoch": 0.9686736280826483,
      "grad_norm": 0.39692055337814275,
      "learning_rate": 8.561949623822142e-05,
      "loss": 0.5243,
      "step": 1090
    },
    {
      "epoch": 0.9775605421017551,
      "grad_norm": 0.40320854459988126,
      "learning_rate": 8.525462050638318e-05,
      "loss": 0.5118,
      "step": 1100
    },
    {
      "epoch": 0.986447456120862,
      "grad_norm": 0.4131748568349956,
      "learning_rate": 8.488597233461561e-05,
      "loss": 0.5235,
      "step": 1110
    },
    {
      "epoch": 0.995334370139969,
      "grad_norm": 0.41202592857681414,
      "learning_rate": 8.451359117031779e-05,
      "loss": 0.5585,
      "step": 1120
    },
    {
      "epoch": 1.0035547656076427,
      "grad_norm": 0.4013408387067405,
      "learning_rate": 8.41375168603396e-05,
      "loss": 0.4623,
      "step": 1130
    },
    {
      "epoch": 1.0124416796267497,
      "grad_norm": 0.4452233233355721,
      "learning_rate": 8.37577896467181e-05,
      "loss": 0.5037,
      "step": 1140
    },
    {
      "epoch": 1.0213285936458565,
      "grad_norm": 0.5432771718155179,
      "learning_rate": 8.337445016237124e-05,
      "loss": 0.5093,
      "step": 1150
    },
    {
      "epoch": 1.0302155076649633,
      "grad_norm": 0.4029693046598972,
      "learning_rate": 8.298753942675e-05,
      "loss": 0.4937,
      "step": 1160
    },
    {
      "epoch": 1.0391024216840703,
      "grad_norm": 0.3993994350002727,
      "learning_rate": 8.2597098841449e-05,
      "loss": 0.4685,
      "step": 1170
    },
    {
      "epoch": 1.047989335703177,
      "grad_norm": 0.3777724940906562,
      "learning_rate": 8.220317018577644e-05,
      "loss": 0.511,
      "step": 1180
    },
    {
      "epoch": 1.056876249722284,
      "grad_norm": 0.40444508674895124,
      "learning_rate": 8.180579561228334e-05,
      "loss": 0.4724,
      "step": 1190
    },
    {
      "epoch": 1.0657631637413907,
      "grad_norm": 0.41035715339314155,
      "learning_rate": 8.140501764225304e-05,
      "loss": 0.4961,
      "step": 1200
    },
    {
      "epoch": 1.0746500777604977,
      "grad_norm": 0.36493762120400597,
      "learning_rate": 8.10008791611512e-05,
      "loss": 0.4901,
      "step": 1210
    },
    {
      "epoch": 1.0835369917796045,
      "grad_norm": 0.42898448028852065,
      "learning_rate": 8.059342341403682e-05,
      "loss": 0.5167,
      "step": 1220
    },
    {
      "epoch": 1.0924239057987113,
      "grad_norm": 0.48395413479444954,
      "learning_rate": 8.01826940009347e-05,
      "loss": 0.4772,
      "step": 1230
    },
    {
      "epoch": 1.1013108198178183,
      "grad_norm": 0.40223840793028104,
      "learning_rate": 7.976873487217011e-05,
      "loss": 0.4957,
      "step": 1240
    },
    {
      "epoch": 1.110197733836925,
      "grad_norm": 0.38502659028336866,
      "learning_rate": 7.935159032366584e-05,
      "loss": 0.4953,
      "step": 1250
    },
    {
      "epoch": 1.119084647856032,
      "grad_norm": 0.38764816491251863,
      "learning_rate": 7.893130499220216e-05,
      "loss": 0.4476,
      "step": 1260
    },
    {
      "epoch": 1.127971561875139,
      "grad_norm": 0.45889717323521484,
      "learning_rate": 7.850792385064063e-05,
      "loss": 0.4794,
      "step": 1270
    },
    {
      "epoch": 1.1368584758942457,
      "grad_norm": 0.38854859200616293,
      "learning_rate": 7.80814922031116e-05,
      "loss": 0.4638,
      "step": 1280
    },
    {
      "epoch": 1.1457453899133525,
      "grad_norm": 0.41802466035112834,
      "learning_rate": 7.765205568016654e-05,
      "loss": 0.5135,
      "step": 1290
    },
    {
      "epoch": 1.1546323039324595,
      "grad_norm": 0.3528349418260402,
      "learning_rate": 7.721966023389519e-05,
      "loss": 0.4993,
      "step": 1300
    },
    {
      "epoch": 1.1635192179515663,
      "grad_norm": 0.4032826691662917,
      "learning_rate": 7.678435213300852e-05,
      "loss": 0.4882,
      "step": 1310
    },
    {
      "epoch": 1.1724061319706731,
      "grad_norm": 0.4002677236236554,
      "learning_rate": 7.634617795788773e-05,
      "loss": 0.4889,
      "step": 1320
    },
    {
      "epoch": 1.1812930459897801,
      "grad_norm": 0.4053835184530219,
      "learning_rate": 7.59051845955998e-05,
      "loss": 0.4792,
      "step": 1330
    },
    {
      "epoch": 1.190179960008887,
      "grad_norm": 0.4147095032838994,
      "learning_rate": 7.546141923488045e-05,
      "loss": 0.4991,
      "step": 1340
    },
    {
      "epoch": 1.1990668740279937,
      "grad_norm": 0.42558049288013244,
      "learning_rate": 7.501492936108455e-05,
      "loss": 0.4874,
      "step": 1350
    },
    {
      "epoch": 1.2079537880471007,
      "grad_norm": 0.4363925340656984,
      "learning_rate": 7.456576275110495e-05,
      "loss": 0.476,
      "step": 1360
    },
    {
      "epoch": 1.2168407020662075,
      "grad_norm": 0.408413649012029,
      "learning_rate": 7.411396746826021e-05,
      "loss": 0.4813,
      "step": 1370
    },
    {
      "epoch": 1.2257276160853143,
      "grad_norm": 0.4122943127407732,
      "learning_rate": 7.36595918571514e-05,
      "loss": 0.5005,
      "step": 1380
    },
    {
      "epoch": 1.2346145301044213,
      "grad_norm": 0.3922384769593953,
      "learning_rate": 7.320268453848905e-05,
      "loss": 0.4988,
      "step": 1390
    },
    {
      "epoch": 1.2435014441235281,
      "grad_norm": 0.45036211951603117,
      "learning_rate": 7.274329440389043e-05,
      "loss": 0.5048,
      "step": 1400
    },
    {
      "epoch": 1.252388358142635,
      "grad_norm": 0.40074673543467576,
      "learning_rate": 7.228147061064789e-05,
      "loss": 0.496,
      "step": 1410
    },
    {
      "epoch": 1.261275272161742,
      "grad_norm": 0.3685245595641009,
      "learning_rate": 7.181726257646874e-05,
      "loss": 0.4766,
      "step": 1420
    },
    {
      "epoch": 1.2701621861808488,
      "grad_norm": 0.42396736462772744,
      "learning_rate": 7.135071997418732e-05,
      "loss": 0.4551,
      "step": 1430
    },
    {
      "epoch": 1.2790491001999555,
      "grad_norm": 0.41926049243655394,
      "learning_rate": 7.08818927264497e-05,
      "loss": 0.4733,
      "step": 1440
    },
    {
      "epoch": 1.2879360142190626,
      "grad_norm": 0.389302212259709,
      "learning_rate": 7.041083100037166e-05,
      "loss": 0.5075,
      "step": 1450
    },
    {
      "epoch": 1.2968229282381694,
      "grad_norm": 0.39402762100064037,
      "learning_rate": 6.993758520217058e-05,
      "loss": 0.482,
      "step": 1460
    },
    {
      "epoch": 1.3057098422572762,
      "grad_norm": 0.38813394249766553,
      "learning_rate": 6.946220597177168e-05,
      "loss": 0.4602,
      "step": 1470
    },
    {
      "epoch": 1.314596756276383,
      "grad_norm": 0.4404435135461677,
      "learning_rate": 6.89847441773892e-05,
      "loss": 0.4423,
      "step": 1480
    },
    {
      "epoch": 1.32348367029549,
      "grad_norm": 0.3923323441525223,
      "learning_rate": 6.850525091008337e-05,
      "loss": 0.4687,
      "step": 1490
    },
    {
      "epoch": 1.3323705843145968,
      "grad_norm": 0.4849235705686047,
      "learning_rate": 6.802377747829317e-05,
      "loss": 0.4822,
      "step": 1500
    },
    {
      "epoch": 1.3412574983337036,
      "grad_norm": 0.5546057726815141,
      "learning_rate": 6.75403754023463e-05,
      "loss": 0.4466,
      "step": 1510
    },
    {
      "epoch": 1.3501444123528104,
      "grad_norm": 0.41976009404682474,
      "learning_rate": 6.705509640894597e-05,
      "loss": 0.4682,
      "step": 1520
    },
    {
      "epoch": 1.3590313263719174,
      "grad_norm": 0.4115934903566676,
      "learning_rate": 6.656799242563603e-05,
      "loss": 0.485,
      "step": 1530
    },
    {
      "epoch": 1.3679182403910242,
      "grad_norm": 0.38082933220729925,
      "learning_rate": 6.607911557524434e-05,
      "loss": 0.4584,
      "step": 1540
    },
    {
      "epoch": 1.376805154410131,
      "grad_norm": 0.32457564563720837,
      "learning_rate": 6.55885181703054e-05,
      "loss": 0.4492,
      "step": 1550
    },
    {
      "epoch": 1.385692068429238,
      "grad_norm": 0.419494763292047,
      "learning_rate": 6.509625270746256e-05,
      "loss": 0.4765,
      "step": 1560
    },
    {
      "epoch": 1.3945789824483448,
      "grad_norm": 0.3694685943345187,
      "learning_rate": 6.460237186185063e-05,
      "loss": 0.4863,
      "step": 1570
    },
    {
      "epoch": 1.4034658964674516,
      "grad_norm": 0.4133005872472072,
      "learning_rate": 6.410692848145933e-05,
      "loss": 0.4729,
      "step": 1580
    },
    {
      "epoch": 1.4123528104865586,
      "grad_norm": 0.3855056677644218,
      "learning_rate": 6.36099755814783e-05,
      "loss": 0.4467,
      "step": 1590
    },
    {
      "epoch": 1.4212397245056654,
      "grad_norm": 0.41507600484399826,
      "learning_rate": 6.31115663386241e-05,
      "loss": 0.4453,
      "step": 1600
    },
    {
      "epoch": 1.4301266385247722,
      "grad_norm": 0.38785621892659927,
      "learning_rate": 6.261175408545008e-05,
      "loss": 0.4294,
      "step": 1610
    },
    {
      "epoch": 1.4390135525438792,
      "grad_norm": 0.38090155838262607,
      "learning_rate": 6.211059230463946e-05,
      "loss": 0.4693,
      "step": 1620
    },
    {
      "epoch": 1.447900466562986,
      "grad_norm": 0.4440098870938031,
      "learning_rate": 6.160813462328244e-05,
      "loss": 0.4518,
      "step": 1630
    },
    {
      "epoch": 1.4567873805820928,
      "grad_norm": 0.5195056696650747,
      "learning_rate": 6.110443480713771e-05,
      "loss": 0.4626,
      "step": 1640
    },
    {
      "epoch": 1.4656742946011998,
      "grad_norm": 0.377108797463372,
      "learning_rate": 6.0599546754879355e-05,
      "loss": 0.4743,
      "step": 1650
    },
    {
      "epoch": 1.4745612086203066,
      "grad_norm": 0.39817189833033795,
      "learning_rate": 6.009352449232921e-05,
      "loss": 0.5028,
      "step": 1660
    },
    {
      "epoch": 1.4834481226394134,
      "grad_norm": 0.3983163585931672,
      "learning_rate": 5.958642216667598e-05,
      "loss": 0.4981,
      "step": 1670
    },
    {
      "epoch": 1.4923350366585204,
      "grad_norm": 0.4186998540122495,
      "learning_rate": 5.907829404068108e-05,
      "loss": 0.4563,
      "step": 1680
    },
    {
      "epoch": 1.5012219506776272,
      "grad_norm": 0.39185054436273936,
      "learning_rate": 5.856919448687226e-05,
      "loss": 0.5043,
      "step": 1690
    },
    {
      "epoch": 1.510108864696734,
      "grad_norm": 0.41165260130032705,
      "learning_rate": 5.8059177981725435e-05,
      "loss": 0.4408,
      "step": 1700
    },
    {
      "epoch": 1.518995778715841,
      "grad_norm": 0.4331017411025975,
      "learning_rate": 5.754829909983539e-05,
      "loss": 0.4802,
      "step": 1710
    },
    {
      "epoch": 1.5278826927349478,
      "grad_norm": 0.42594318994325875,
      "learning_rate": 5.703661250807599e-05,
      "loss": 0.4227,
      "step": 1720
    },
    {
      "epoch": 1.5367696067540546,
      "grad_norm": 0.490303983525434,
      "learning_rate": 5.6524172959750596e-05,
      "loss": 0.4633,
      "step": 1730
    },
    {
      "epoch": 1.5456565207731616,
      "grad_norm": 0.3837165825141704,
      "learning_rate": 5.601103528873304e-05,
      "loss": 0.4643,
      "step": 1740
    },
    {
      "epoch": 1.5545434347922684,
      "grad_norm": 0.3861445480533416,
      "learning_rate": 5.549725440360015e-05,
      "loss": 0.4783,
      "step": 1750
    },
    {
      "epoch": 1.5634303488113752,
      "grad_norm": 0.3836144191226605,
      "learning_rate": 5.498288528175628e-05,
      "loss": 0.5181,
      "step": 1760
    },
    {
      "epoch": 1.5723172628304822,
      "grad_norm": 0.4136441539586207,
      "learning_rate": 5.4467982963550344e-05,
      "loss": 0.4348,
      "step": 1770
    },
    {
      "epoch": 1.581204176849589,
      "grad_norm": 0.43977415164080336,
      "learning_rate": 5.3952602546386234e-05,
      "loss": 0.4606,
      "step": 1780
    },
    {
      "epoch": 1.5900910908686958,
      "grad_norm": 0.4073720242535248,
      "learning_rate": 5.3436799178827067e-05,
      "loss": 0.4473,
      "step": 1790
    },
    {
      "epoch": 1.5989780048878028,
      "grad_norm": 0.40005535682986215,
      "learning_rate": 5.2920628054694e-05,
      "loss": 0.4469,
      "step": 1800
    },
    {
      "epoch": 1.6078649189069094,
      "grad_norm": 0.36933534894749775,
      "learning_rate": 5.2404144407160195e-05,
      "loss": 0.4721,
      "step": 1810
    },
    {
      "epoch": 1.6167518329260164,
      "grad_norm": 0.3935078892512638,
      "learning_rate": 5.188740350284057e-05,
      "loss": 0.5018,
      "step": 1820
    },
    {
      "epoch": 1.6256387469451234,
      "grad_norm": 0.38622112903429345,
      "learning_rate": 5.1370460635877896e-05,
      "loss": 0.4877,
      "step": 1830
    },
    {
      "epoch": 1.63452566096423,
      "grad_norm": 0.40145596945710593,
      "learning_rate": 5.085337112202609e-05,
      "loss": 0.4457,
      "step": 1840
    },
    {
      "epoch": 1.643412574983337,
      "grad_norm": 0.4102854370554393,
      "learning_rate": 5.0336190292731124e-05,
      "loss": 0.4281,
      "step": 1850
    },
    {
      "epoch": 1.652299489002444,
      "grad_norm": 0.38584563679325556,
      "learning_rate": 4.981897348921021e-05,
      "loss": 0.4551,
      "step": 1860
    },
    {
      "epoch": 1.6611864030215506,
      "grad_norm": 0.39446132331217854,
      "learning_rate": 4.930177605652999e-05,
      "loss": 0.4559,
      "step": 1870
    },
    {
      "epoch": 1.6700733170406576,
      "grad_norm": 0.3713251831795751,
      "learning_rate": 4.878465333768432e-05,
      "loss": 0.4204,
      "step": 1880
    },
    {
      "epoch": 1.6789602310597647,
      "grad_norm": 0.45835243783869367,
      "learning_rate": 4.826766066767227e-05,
      "loss": 0.4679,
      "step": 1890
    },
    {
      "epoch": 1.6878471450788712,
      "grad_norm": 0.4276009594054309,
      "learning_rate": 4.775085336757699e-05,
      "loss": 0.4688,
      "step": 1900
    },
    {
      "epoch": 1.6967340590979783,
      "grad_norm": 0.42664312037321367,
      "learning_rate": 4.723428673864598e-05,
      "loss": 0.4285,
      "step": 1910
    },
    {
      "epoch": 1.705620973117085,
      "grad_norm": 0.4358295437186676,
      "learning_rate": 4.671801605637359e-05,
      "loss": 0.4627,
      "step": 1920
    },
    {
      "epoch": 1.7145078871361918,
      "grad_norm": 0.374706690320583,
      "learning_rate": 4.620209656458626e-05,
      "loss": 0.4398,
      "step": 1930
    },
    {
      "epoch": 1.7233948011552989,
      "grad_norm": 0.4457009820468829,
      "learning_rate": 4.568658346953109e-05,
      "loss": 0.5121,
      "step": 1940
    },
    {
      "epoch": 1.7322817151744057,
      "grad_norm": 0.368458252336249,
      "learning_rate": 4.5171531933968476e-05,
      "loss": 0.4713,
      "step": 1950
    },
    {
      "epoch": 1.7411686291935125,
      "grad_norm": 0.39713455129800895,
      "learning_rate": 4.465699707126941e-05,
      "loss": 0.4276,
      "step": 1960
    },
    {
      "epoch": 1.7500555432126195,
      "grad_norm": 0.3757731288010632,
      "learning_rate": 4.414303393951797e-05,
      "loss": 0.4747,
      "step": 1970
    },
    {
      "epoch": 1.7589424572317263,
      "grad_norm": 0.3507676902102825,
      "learning_rate": 4.362969753561992e-05,
      "loss": 0.4307,
      "step": 1980
    },
    {
      "epoch": 1.767829371250833,
      "grad_norm": 0.43050367021313496,
      "learning_rate": 4.3117042789417586e-05,
      "loss": 0.4482,
      "step": 1990
    },
    {
      "epoch": 1.77671628526994,
      "grad_norm": 0.39002796343619145,
      "learning_rate": 4.260512455781221e-05,
      "loss": 0.4861,
      "step": 2000
    },
    {
      "epoch": 1.7856031992890469,
      "grad_norm": 0.4641479654677653,
      "learning_rate": 4.209399761889386e-05,
      "loss": 0.4414,
      "step": 2010
    },
    {
      "epoch": 1.7944901133081537,
      "grad_norm": 0.38116971747784023,
      "learning_rate": 4.15837166660799e-05,
      "loss": 0.4697,
      "step": 2020
    },
    {
      "epoch": 1.8033770273272607,
      "grad_norm": 0.45740114473278587,
      "learning_rate": 4.1074336302262466e-05,
      "loss": 0.4693,
      "step": 2030
    },
    {
      "epoch": 1.8122639413463675,
      "grad_norm": 0.5034867129420695,
      "learning_rate": 4.056591103396573e-05,
      "loss": 0.4661,
      "step": 2040
    },
    {
      "epoch": 1.8211508553654743,
      "grad_norm": 0.4314004527982038,
      "learning_rate": 4.0058495265513295e-05,
      "loss": 0.4459,
      "step": 2050
    },
    {
      "epoch": 1.8300377693845813,
      "grad_norm": 0.4700784531845515,
      "learning_rate": 3.9552143293206704e-05,
      "loss": 0.4354,
      "step": 2060
    },
    {
      "epoch": 1.838924683403688,
      "grad_norm": 0.40995684832689927,
      "learning_rate": 3.90469092995154e-05,
      "loss": 0.4627,
      "step": 2070
    },
    {
      "epoch": 1.8478115974227949,
      "grad_norm": 0.3975020386204274,
      "learning_rate": 3.854284734727894e-05,
      "loss": 0.4456,
      "step": 2080
    },
    {
      "epoch": 1.856698511441902,
      "grad_norm": 0.3993630293656385,
      "learning_rate": 3.804001137392193e-05,
      "loss": 0.4599,
      "step": 2090
    },
    {
      "epoch": 1.8655854254610087,
      "grad_norm": 0.41616153262073285,
      "learning_rate": 3.7538455185682406e-05,
      "loss": 0.4329,
      "step": 2100
    },
    {
      "epoch": 1.8744723394801155,
      "grad_norm": 0.48327836416582654,
      "learning_rate": 3.7038232451854335e-05,
      "loss": 0.4399,
      "step": 2110
    },
    {
      "epoch": 1.8833592534992225,
      "grad_norm": 0.4100277722879265,
      "learning_rate": 3.653939669904468e-05,
      "loss": 0.4377,
      "step": 2120
    },
    {
      "epoch": 1.8922461675183293,
      "grad_norm": 0.4832100643857103,
      "learning_rate": 3.604200130544569e-05,
      "loss": 0.4827,
      "step": 2130
    },
    {
      "epoch": 1.901133081537436,
      "grad_norm": 0.3704744533889661,
      "learning_rate": 3.5546099495123235e-05,
      "loss": 0.4528,
      "step": 2140
    },
    {
      "epoch": 1.9100199955565431,
      "grad_norm": 0.40625085337007266,
      "learning_rate": 3.5051744332321466e-05,
      "loss": 0.4823,
      "step": 2150
    },
    {
      "epoch": 1.91890690957565,
      "grad_norm": 0.4332482793386945,
      "learning_rate": 3.4558988715784677e-05,
      "loss": 0.4425,
      "step": 2160
    },
    {
      "epoch": 1.9277938235947567,
      "grad_norm": 0.4949176351726469,
      "learning_rate": 3.406788537309685e-05,
      "loss": 0.4835,
      "step": 2170
    },
    {
      "epoch": 1.9366807376138637,
      "grad_norm": 0.3716174367124373,
      "learning_rate": 3.357848685503949e-05,
      "loss": 0.432,
      "step": 2180
    },
    {
      "epoch": 1.9455676516329703,
      "grad_norm": 0.3988869410925081,
      "learning_rate": 3.309084552996841e-05,
      "loss": 0.4461,
      "step": 2190
    },
    {
      "epoch": 1.9544545656520773,
      "grad_norm": 0.4285404874328777,
      "learning_rate": 3.260501357821003e-05,
      "loss": 0.4868,
      "step": 2200
    },
    {
      "epoch": 1.9633414796711843,
      "grad_norm": 0.4175544144479544,
      "learning_rate": 3.21210429864778e-05,
      "loss": 0.4643,
      "step": 2210
    },
    {
      "epoch": 1.972228393690291,
      "grad_norm": 0.39698059708367195,
      "learning_rate": 3.163898554230932e-05,
      "loss": 0.4598,
      "step": 2220
    },
    {
      "epoch": 1.981115307709398,
      "grad_norm": 0.38408489953029507,
      "learning_rate": 3.1158892828524765e-05,
      "loss": 0.4717,
      "step": 2230
    },
    {
      "epoch": 1.990002221728505,
      "grad_norm": 0.4376303126024845,
      "learning_rate": 3.068081621770729e-05,
      "loss": 0.4169,
      "step": 2240
    },
    {
      "epoch": 1.9988891357476115,
      "grad_norm": 0.41509516320014095,
      "learning_rate": 3.020480686670585e-05,
      "loss": 0.4388,
      "step": 2250
    },
    {
      "epoch": 2.0071095312152853,
      "grad_norm": 0.39154065335630467,
      "learning_rate": 2.9730915711161122e-05,
      "loss": 0.3532,
      "step": 2260
    },
    {
      "epoch": 2.0159964452343924,
      "grad_norm": 0.4341318173374019,
      "learning_rate": 2.9259193460055117e-05,
      "loss": 0.374,
      "step": 2270
    },
    {
      "epoch": 2.0248833592534994,
      "grad_norm": 0.4607639796401228,
      "learning_rate": 2.8789690590285046e-05,
      "loss": 0.3999,
      "step": 2280
    },
    {
      "epoch": 2.033770273272606,
      "grad_norm": 0.5604583880148326,
      "learning_rate": 2.8322457341262044e-05,
      "loss": 0.3925,
      "step": 2290
    },
    {
      "epoch": 2.042657187291713,
      "grad_norm": 0.6007381803788943,
      "learning_rate": 2.785754370953515e-05,
      "loss": 0.3959,
      "step": 2300
    },
    {
      "epoch": 2.05154410131082,
      "grad_norm": 0.41956714324509636,
      "learning_rate": 2.739499944344157e-05,
      "loss": 0.3826,
      "step": 2310
    },
    {
      "epoch": 2.0604310153299266,
      "grad_norm": 0.4428896278169752,
      "learning_rate": 2.6934874037783244e-05,
      "loss": 0.412,
      "step": 2320
    },
    {
      "epoch": 2.0693179293490336,
      "grad_norm": 0.43743242650635256,
      "learning_rate": 2.6477216728530553e-05,
      "loss": 0.3753,
      "step": 2330
    },
    {
      "epoch": 2.0782048433681406,
      "grad_norm": 0.5088295224409219,
      "learning_rate": 2.6022076487553947e-05,
      "loss": 0.3999,
      "step": 2340
    },
    {
      "epoch": 2.087091757387247,
      "grad_norm": 0.5249590819038285,
      "learning_rate": 2.5569502017383585e-05,
      "loss": 0.4067,
      "step": 2350
    },
    {
      "epoch": 2.095978671406354,
      "grad_norm": 0.4952662351626793,
      "learning_rate": 2.511954174599792e-05,
      "loss": 0.4331,
      "step": 2360
    },
    {
      "epoch": 2.104865585425461,
      "grad_norm": 0.48003329669195055,
      "learning_rate": 2.4672243821641656e-05,
      "loss": 0.4031,
      "step": 2370
    },
    {
      "epoch": 2.113752499444568,
      "grad_norm": 0.4768386853756778,
      "learning_rate": 2.4227656107673542e-05,
      "loss": 0.3947,
      "step": 2380
    },
    {
      "epoch": 2.122639413463675,
      "grad_norm": 0.45848403129764714,
      "learning_rate": 2.3785826177444857e-05,
      "loss": 0.3938,
      "step": 2390
    },
    {
      "epoch": 2.1315263274827814,
      "grad_norm": 0.5221552636265019,
      "learning_rate": 2.334680130920865e-05,
      "loss": 0.3947,
      "step": 2400
    },
    {
      "epoch": 2.1404132415018884,
      "grad_norm": 0.5868358480638626,
      "learning_rate": 2.291062848106083e-05,
      "loss": 0.4031,
      "step": 2410
    },
    {
      "epoch": 2.1493001555209954,
      "grad_norm": 0.5329223911395967,
      "learning_rate": 2.2477354365913212e-05,
      "loss": 0.3958,
      "step": 2420
    },
    {
      "epoch": 2.1581870695401024,
      "grad_norm": 1.2072341737166252,
      "learning_rate": 2.2047025326499172e-05,
      "loss": 0.3699,
      "step": 2430
    },
    {
      "epoch": 2.167073983559209,
      "grad_norm": 0.4749249895800481,
      "learning_rate": 2.1619687410412725e-05,
      "loss": 0.4223,
      "step": 2440
    },
    {
      "epoch": 2.175960897578316,
      "grad_norm": 0.4208404188175373,
      "learning_rate": 2.1195386345181036e-05,
      "loss": 0.4138,
      "step": 2450
    },
    {
      "epoch": 2.1848478115974226,
      "grad_norm": 0.5203080004995487,
      "learning_rate": 2.077416753337143e-05,
      "loss": 0.3999,
      "step": 2460
    },
    {
      "epoch": 2.1937347256165296,
      "grad_norm": 0.4568912978493221,
      "learning_rate": 2.0356076047733025e-05,
      "loss": 0.4196,
      "step": 2470
    },
    {
      "epoch": 2.2026216396356366,
      "grad_norm": 0.49146720046103914,
      "learning_rate": 1.9941156626373635e-05,
      "loss": 0.4039,
      "step": 2480
    },
    {
      "epoch": 2.211508553654743,
      "grad_norm": 0.44433689345225985,
      "learning_rate": 1.9529453667972664e-05,
      "loss": 0.4042,
      "step": 2490
    },
    {
      "epoch": 2.22039546767385,
      "grad_norm": 0.5042271921115243,
      "learning_rate": 1.9121011227030128e-05,
      "loss": 0.4198,
      "step": 2500
    },
    {
      "epoch": 2.2292823816929572,
      "grad_norm": 0.4760782284089477,
      "learning_rate": 1.8715873009152558e-05,
      "loss": 0.3871,
      "step": 2510
    },
    {
      "epoch": 2.238169295712064,
      "grad_norm": 0.502114265587843,
      "learning_rate": 1.8314082366376335e-05,
      "loss": 0.4345,
      "step": 2520
    },
    {
      "epoch": 2.247056209731171,
      "grad_norm": 0.4347687082211578,
      "learning_rate": 1.7915682292528686e-05,
      "loss": 0.3934,
      "step": 2530
    },
    {
      "epoch": 2.255943123750278,
      "grad_norm": 0.5079680086617029,
      "learning_rate": 1.7520715418627204e-05,
      "loss": 0.3853,
      "step": 2540
    },
    {
      "epoch": 2.2648300377693844,
      "grad_norm": 0.5245700152190343,
      "learning_rate": 1.7129224008318044e-05,
      "loss": 0.4305,
      "step": 2550
    },
    {
      "epoch": 2.2737169517884914,
      "grad_norm": 0.5246447262347683,
      "learning_rate": 1.6741249953353433e-05,
      "loss": 0.419,
      "step": 2560
    },
    {
      "epoch": 2.2826038658075984,
      "grad_norm": 0.4869024105550571,
      "learning_rate": 1.6356834769109113e-05,
      "loss": 0.4012,
      "step": 2570
    },
    {
      "epoch": 2.291490779826705,
      "grad_norm": 0.478821121251532,
      "learning_rate": 1.5976019590141928e-05,
      "loss": 0.4037,
      "step": 2580
    },
    {
      "epoch": 2.300377693845812,
      "grad_norm": 0.5448832312913646,
      "learning_rate": 1.5598845165788133e-05,
      "loss": 0.4096,
      "step": 2590
    },
    {
      "epoch": 2.309264607864919,
      "grad_norm": 0.4913210927480958,
      "learning_rate": 1.5225351855803115e-05,
      "loss": 0.3804,
      "step": 2600
    },
    {
      "epoch": 2.3181515218840256,
      "grad_norm": 0.4693789360087432,
      "learning_rate": 1.4855579626042542e-05,
      "loss": 0.4099,
      "step": 2610
    },
    {
      "epoch": 2.3270384359031326,
      "grad_norm": 0.46709671270608377,
      "learning_rate": 1.4489568044185914e-05,
      "loss": 0.3801,
      "step": 2620
    },
    {
      "epoch": 2.3359253499222397,
      "grad_norm": 0.5223184764929906,
      "learning_rate": 1.4127356275502529e-05,
      "loss": 0.4,
      "step": 2630
    },
    {
      "epoch": 2.3448122639413462,
      "grad_norm": 0.5080187243353966,
      "learning_rate": 1.3768983078660568e-05,
      "loss": 0.4253,
      "step": 2640
    },
    {
      "epoch": 2.3536991779604532,
      "grad_norm": 0.5383957532823087,
      "learning_rate": 1.341448680157979e-05,
      "loss": 0.4101,
      "step": 2650
    },
    {
      "epoch": 2.3625860919795603,
      "grad_norm": 0.5111248610414186,
      "learning_rate": 1.3063905377328007e-05,
      "loss": 0.4068,
      "step": 2660
    },
    {
      "epoch": 2.371473005998667,
      "grad_norm": 0.5776641648180882,
      "learning_rate": 1.2717276320062055e-05,
      "loss": 0.3731,
      "step": 2670
    },
    {
      "epoch": 2.380359920017774,
      "grad_norm": 0.4654569321786945,
      "learning_rate": 1.237463672101361e-05,
      "loss": 0.3955,
      "step": 2680
    },
    {
      "epoch": 2.389246834036881,
      "grad_norm": 0.46845964626468684,
      "learning_rate": 1.2036023244520156e-05,
      "loss": 0.3788,
      "step": 2690
    },
    {
      "epoch": 2.3981337480559874,
      "grad_norm": 0.5168179460783179,
      "learning_rate": 1.1701472124101765e-05,
      "loss": 0.3877,
      "step": 2700
    },
    {
      "epoch": 2.4070206620750945,
      "grad_norm": 0.4690032317170526,
      "learning_rate": 1.1371019158583879e-05,
      "loss": 0.3731,
      "step": 2710
    },
    {
      "epoch": 2.4159075760942015,
      "grad_norm": 0.5247176584223038,
      "learning_rate": 1.1044699708266592e-05,
      "loss": 0.3906,
      "step": 2720
    },
    {
      "epoch": 2.424794490113308,
      "grad_norm": 0.489058950056458,
      "learning_rate": 1.072254869114101e-05,
      "loss": 0.412,
      "step": 2730
    },
    {
      "epoch": 2.433681404132415,
      "grad_norm": 0.5044588769392964,
      "learning_rate": 1.0404600579152701e-05,
      "loss": 0.4117,
      "step": 2740
    },
    {
      "epoch": 2.4425683181515216,
      "grad_norm": 0.47337612621886554,
      "learning_rate": 1.009088939451312e-05,
      "loss": 0.371,
      "step": 2750
    },
    {
      "epoch": 2.4514552321706287,
      "grad_norm": 0.5664292727951864,
      "learning_rate": 9.781448706058983e-06,
      "loss": 0.3727,
      "step": 2760
    },
    {
      "epoch": 2.4603421461897357,
      "grad_norm": 0.5194446275745669,
      "learning_rate": 9.476311625660229e-06,
      "loss": 0.3969,
      "step": 2770
    },
    {
      "epoch": 2.4692290602088427,
      "grad_norm": 0.4443199476786439,
      "learning_rate": 9.175510804676868e-06,
      "loss": 0.388,
      "step": 2780
    },
    {
      "epoch": 2.4781159742279493,
      "grad_norm": 0.5012354468809854,
      "learning_rate": 8.879078430465082e-06,
      "loss": 0.3726,
      "step": 2790
    },
    {
      "epoch": 2.4870028882470563,
      "grad_norm": 0.4869316985320863,
      "learning_rate": 8.587046222933038e-06,
      "loss": 0.4147,
      "step": 2800
    },
    {
      "epoch": 2.495889802266163,
      "grad_norm": 0.5395011633507619,
      "learning_rate": 8.299445431146686e-06,
      "loss": 0.386,
      "step": 2810
    },
    {
      "epoch": 2.50477671628527,
      "grad_norm": 0.4732634337368698,
      "learning_rate": 8.016306829985848e-06,
      "loss": 0.3974,
      "step": 2820
    },
    {
      "epoch": 2.513663630304377,
      "grad_norm": 0.5318210241764296,
      "learning_rate": 7.737660716851269e-06,
      "loss": 0.3903,
      "step": 2830
    },
    {
      "epoch": 2.522550544323484,
      "grad_norm": 0.497018722258644,
      "learning_rate": 7.463536908422508e-06,
      "loss": 0.4252,
      "step": 2840
    },
    {
      "epoch": 2.5314374583425905,
      "grad_norm": 0.47820890032603713,
      "learning_rate": 7.193964737467474e-06,
      "loss": 0.3925,
      "step": 2850
    },
    {
      "epoch": 2.5403243723616975,
      "grad_norm": 0.5389202110342733,
      "learning_rate": 6.9289730497036074e-06,
      "loss": 0.4092,
      "step": 2860
    },
    {
      "epoch": 2.549211286380804,
      "grad_norm": 0.4985498231026001,
      "learning_rate": 6.668590200711222e-06,
      "loss": 0.3628,
      "step": 2870
    },
    {
      "epoch": 2.558098200399911,
      "grad_norm": 0.48799501094001185,
      "learning_rate": 6.412844052899347e-06,
      "loss": 0.3971,
      "step": 2880
    },
    {
      "epoch": 2.566985114419018,
      "grad_norm": 0.46580040378213305,
      "learning_rate": 6.161761972524283e-06,
      "loss": 0.4085,
      "step": 2890
    },
    {
      "epoch": 2.575872028438125,
      "grad_norm": 0.6643800303296826,
      "learning_rate": 5.91537082676119e-06,
      "loss": 0.3684,
      "step": 2900
    },
    {
      "epoch": 2.5847589424572317,
      "grad_norm": 0.5209595458583458,
      "learning_rate": 5.673696980829274e-06,
      "loss": 0.3609,
      "step": 2910
    },
    {
      "epoch": 2.5936458564763387,
      "grad_norm": 0.49741554601242466,
      "learning_rate": 5.436766295170426e-06,
      "loss": 0.3806,
      "step": 2920
    },
    {
      "epoch": 2.6025327704954453,
      "grad_norm": 0.5204008932601303,
      "learning_rate": 5.204604122682138e-06,
      "loss": 0.3855,
      "step": 2930
    },
    {
      "epoch": 2.6114196845145523,
      "grad_norm": 0.5591584949204789,
      "learning_rate": 4.977235306004535e-06,
      "loss": 0.4149,
      "step": 2940
    },
    {
      "epoch": 2.6203065985336593,
      "grad_norm": 0.5001072665105014,
      "learning_rate": 4.754684174862045e-06,
      "loss": 0.383,
      "step": 2950
    },
    {
      "epoch": 2.629193512552766,
      "grad_norm": 0.5367437442611495,
      "learning_rate": 4.536974543460071e-06,
      "loss": 0.3662,
      "step": 2960
    },
    {
      "epoch": 2.638080426571873,
      "grad_norm": 0.620731964497772,
      "learning_rate": 4.3241297079366585e-06,
      "loss": 0.4062,
      "step": 2970
    },
    {
      "epoch": 2.64696734059098,
      "grad_norm": 0.5014385508375206,
      "learning_rate": 4.1161724438697315e-06,
      "loss": 0.4153,
      "step": 2980
    },
    {
      "epoch": 2.6558542546100865,
      "grad_norm": 0.5671688943017134,
      "learning_rate": 3.913125003839957e-06,
      "loss": 0.3927,
      "step": 2990
    },
    {
      "epoch": 2.6647411686291935,
      "grad_norm": 0.5501678926757572,
      "learning_rate": 3.7150091150495838e-06,
      "loss": 0.3848,
      "step": 3000
    },
    {
      "epoch": 2.6736280826483005,
      "grad_norm": 0.5650204113200213,
      "learning_rate": 3.52184597699754e-06,
      "loss": 0.3999,
      "step": 3010
    },
    {
      "epoch": 2.682514996667407,
      "grad_norm": 0.47068190538738586,
      "learning_rate": 3.33365625921096e-06,
      "loss": 0.3824,
      "step": 3020
    },
    {
      "epoch": 2.691401910686514,
      "grad_norm": 0.5947447271513175,
      "learning_rate": 3.150460099033403e-06,
      "loss": 0.3869,
      "step": 3030
    },
    {
      "epoch": 2.7002888247056207,
      "grad_norm": 0.4852343712605809,
      "learning_rate": 2.9722770994700943e-06,
      "loss": 0.3655,
      "step": 3040
    },
    {
      "epoch": 2.7091757387247277,
      "grad_norm": 0.43849081658147526,
      "learning_rate": 2.7991263270902458e-06,
      "loss": 0.4138,
      "step": 3050
    },
    {
      "epoch": 2.7180626527438347,
      "grad_norm": 0.5095134493013971,
      "learning_rate": 2.6310263099868615e-06,
      "loss": 0.382,
      "step": 3060
    },
    {
      "epoch": 2.7269495667629418,
      "grad_norm": 0.4338783125157625,
      "learning_rate": 2.467995035794124e-06,
      "loss": 0.3488,
      "step": 3070
    },
    {
      "epoch": 2.7358364807820483,
      "grad_norm": 0.49253103456023184,
      "learning_rate": 2.3100499497625937e-06,
      "loss": 0.3819,
      "step": 3080
    },
    {
      "epoch": 2.7447233948011553,
      "grad_norm": 0.4867639315775365,
      "learning_rate": 2.157207952892498e-06,
      "loss": 0.3498,
      "step": 3090
    },
    {
      "epoch": 2.753610308820262,
      "grad_norm": 0.5044345354027083,
      "learning_rate": 2.009485400125233e-06,
      "loss": 0.4064,
      "step": 3100
    },
    {
      "epoch": 2.762497222839369,
      "grad_norm": 0.5357947002502398,
      "learning_rate": 1.8668980985932561e-06,
      "loss": 0.364,
      "step": 3110
    },
    {
      "epoch": 2.771384136858476,
      "grad_norm": 0.4820087634187952,
      "learning_rate": 1.7294613059286758e-06,
      "loss": 0.3632,
      "step": 3120
    },
    {
      "epoch": 2.780271050877583,
      "grad_norm": 0.5717799543259896,
      "learning_rate": 1.5971897286305825e-06,
      "loss": 0.3749,
      "step": 3130
    },
    {
      "epoch": 2.7891579648966895,
      "grad_norm": 0.522869667951234,
      "learning_rate": 1.470097520491376e-06,
      "loss": 0.3781,
      "step": 3140
    },
    {
      "epoch": 2.7980448789157966,
      "grad_norm": 0.4336653951982293,
      "learning_rate": 1.3481982810822302e-06,
      "loss": 0.4173,
      "step": 3150
    },
    {
      "epoch": 2.806931792934903,
      "grad_norm": 0.5247649551652138,
      "learning_rate": 1.231505054297849e-06,
      "loss": 0.3891,
      "step": 3160
    },
    {
      "epoch": 2.81581870695401,
      "grad_norm": 0.49920591552620835,
      "learning_rate": 1.1200303269607359e-06,
      "loss": 0.3519,
      "step": 3170
    },
    {
      "epoch": 2.824705620973117,
      "grad_norm": 0.536288737645205,
      "learning_rate": 1.013786027484981e-06,
      "loss": 0.3888,
      "step": 3180
    },
    {
      "epoch": 2.833592534992224,
      "grad_norm": 0.48310280887751683,
      "learning_rate": 9.127835245999139e-07,
      "loss": 0.3748,
      "step": 3190
    },
    {
      "epoch": 2.8424794490113308,
      "grad_norm": 0.4972986965939712,
      "learning_rate": 8.170336261335343e-07,
      "loss": 0.3816,
      "step": 3200
    },
    {
      "epoch": 2.851366363030438,
      "grad_norm": 0.5078623272073922,
      "learning_rate": 7.265465778560355e-07,
      "loss": 0.3968,
      "step": 3210
    },
    {
      "epoch": 2.8602532770495444,
      "grad_norm": 0.4965682150742223,
      "learning_rate": 6.413320623834651e-07,
      "loss": 0.3826,
      "step": 3220
    },
    {
      "epoch": 2.8691401910686514,
      "grad_norm": 0.49710757066413847,
      "learning_rate": 5.6139919814161e-07,
      "loss": 0.3958,
      "step": 3230
    },
    {
      "epoch": 2.8780271050877584,
      "grad_norm": 0.5882686588131821,
      "learning_rate": 4.867565383902761e-07,
      "loss": 0.3808,
      "step": 3240
    },
    {
      "epoch": 2.8869140191068654,
      "grad_norm": 0.5286162292020251,
      "learning_rate": 4.174120703080597e-07,
      "loss": 0.3687,
      "step": 3250
    },
    {
      "epoch": 2.895800933125972,
      "grad_norm": 0.47396529034539314,
      "learning_rate": 3.5337321413765334e-07,
      "loss": 0.3834,
      "step": 3260
    },
    {
      "epoch": 2.904687847145079,
      "grad_norm": 0.5331798989753909,
      "learning_rate": 2.9464682239184747e-07,
      "loss": 0.4006,
      "step": 3270
    },
    {
      "epoch": 2.9135747611641856,
      "grad_norm": 0.5031184389736771,
      "learning_rate": 2.4123917912027285e-07,
      "loss": 0.3807,
      "step": 3280
    },
    {
      "epoch": 2.9224616751832926,
      "grad_norm": 0.5400987795219866,
      "learning_rate": 1.9315599923698802e-07,
      "loss": 0.3824,
      "step": 3290
    },
    {
      "epoch": 2.9313485892023996,
      "grad_norm": 0.5444540200285872,
      "learning_rate": 1.5040242790892444e-07,
      "loss": 0.4026,
      "step": 3300
    },
    {
      "epoch": 2.940235503221506,
      "grad_norm": 0.6005052243400032,
      "learning_rate": 1.1298304000533778e-07,
      "loss": 0.4035,
      "step": 3310
    },
    {
      "epoch": 2.949122417240613,
      "grad_norm": 0.5658397033488638,
      "learning_rate": 8.090183960827725e-08,
      "loss": 0.3821,
      "step": 3320
    },
    {
      "epoch": 2.95800933125972,
      "grad_norm": 0.5103952696082494,
      "learning_rate": 5.416225958412291e-08,
      "loss": 0.398,
      "step": 3330
    },
    {
      "epoch": 2.966896245278827,
      "grad_norm": 0.528848722145664,
      "learning_rate": 3.276716121624057e-08,
      "loss": 0.4046,
      "step": 3340
    },
    {
      "epoch": 2.975783159297934,
      "grad_norm": 0.5194204671806901,
      "learning_rate": 1.671883389882112e-08,
      "loss": 0.378,
      "step": 3350
    },
    {
      "epoch": 2.984670073317041,
      "grad_norm": 0.5737876762570082,
      "learning_rate": 6.0189948919042725e-09,
      "loss": 0.3723,
      "step": 3360
    },
    {
      "epoch": 2.9935569873361474,
      "grad_norm": 0.5124136985815583,
      "learning_rate": 6.68789137597825e-10,
      "loss": 0.3519,
      "step": 3370
    },
    {
      "epoch": 2.998000444345701,
      "step": 3375,
      "total_flos": 1.1491333522849792e+16,
      "train_loss": 0.5098538473270557,
      "train_runtime": 185093.8897,
      "train_samples_per_second": 2.043,
      "train_steps_per_second": 0.018
    }
  ],
  "logging_steps": 10,
  "max_steps": 3375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1491333522849792e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
